version: '3.8'

services:
  local-maxgpt:
    image: localai/localai:latest-gpu-nvidia-cuda-12
    container_name: local-maxgpt
    restart: unless-stopped
    ports:
      - "8080:8080"  # API and Web UI
    environment:
      - DEBUG=false
      - MODELS_PATH=/models
      - THREADS=8
      - CONTEXT_SIZE=2048
      - GPU_LAYERS=-1
      - PRELOAD_MODELS_CONFIG=/models
    volumes:
      - ./models:/models
      - ./data:/data
      - ./images:/tmp/generated/images/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
